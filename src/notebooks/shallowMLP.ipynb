{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "0ioXSvXksW5t"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fillies/Documents/moon/kilter/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add parent directory (src/) to sys.path\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "\n",
    "from Data_Handler import get_data\n",
    "import json\n",
    "import os\n",
    "import zipfile\n",
    "from collections import Counter\n",
    "from typing import Dict\n",
    "import shutil\n",
    "import sqlite3, json, os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from timeit import default_timer as timer\n",
    "from tqdm.auto import tqdm\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torchmetrics.classification import MulticlassAccuracy\n",
    "import optuna\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in /home/fillies/Documents/moon/kilter/.venv/lib/python3.12/site-packages (4.5.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /home/fillies/Documents/moon/kilter/.venv/lib/python3.12/site-packages (from optuna) (1.16.5)\n",
      "Requirement already satisfied: colorlog in /home/fillies/Documents/moon/kilter/.venv/lib/python3.12/site-packages (from optuna) (6.9.0)\n",
      "Requirement already satisfied: numpy in /home/fillies/Documents/moon/kilter/.venv/lib/python3.12/site-packages (from optuna) (2.3.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/fillies/Documents/moon/kilter/.venv/lib/python3.12/site-packages (from optuna) (25.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /home/fillies/Documents/moon/kilter/.venv/lib/python3.12/site-packages (from optuna) (2.0.43)\n",
      "Requirement already satisfied: tqdm in /home/fillies/Documents/moon/kilter/.venv/lib/python3.12/site-packages (from optuna) (4.67.1)\n",
      "Requirement already satisfied: PyYAML in /home/fillies/Documents/moon/kilter/.venv/lib/python3.12/site-packages (from optuna) (6.0.2)\n",
      "Requirement already satisfied: Mako in /home/fillies/Documents/moon/kilter/.venv/lib/python3.12/site-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in /home/fillies/Documents/moon/kilter/.venv/lib/python3.12/site-packages (from alembic>=1.5.0->optuna) (4.15.0)\n",
      "Requirement already satisfied: greenlet>=1 in /home/fillies/Documents/moon/kilter/.venv/lib/python3.12/site-packages (from sqlalchemy>=1.4.2->optuna) (3.2.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /home/fillies/Documents/moon/kilter/.venv/lib/python3.12/site-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4004,
     "status": "ok",
     "timestamp": 1758101392172,
     "user": {
      "displayName": "Fritz Hocker",
      "userId": "14167107387628010693"
     },
     "user_tz": -120
    },
    "id": "_d5WlH-2scBY",
    "outputId": "28d391ec-7bad-43af-a074-04c2420886e1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(            route_id     difficulty        hold_id      token_num  \\\n",
       " count  452057.000000  452057.000000  452057.000000  452057.000000   \n",
       " mean   106045.795484    1242.255280     265.403715    1304.119410   \n",
       " std     65642.474089       4.485806     130.137169     130.992049   \n",
       " min         2.000000    1233.000000       3.000000    1073.000000   \n",
       " 25%     47390.000000    1239.000000     176.000000    1199.000000   \n",
       " 50%    105517.000000    1243.000000     277.000000    1287.000000   \n",
       " 75%    162363.000000    1246.000000     363.000000    1389.000000   \n",
       " max    222622.000000    1253.000000     526.000000    1599.000000   \n",
       " \n",
       "                    x              y         set_id  \n",
       " count  452057.000000  452057.000000  452057.000000  \n",
       " mean       72.420106      78.156463       5.165099  \n",
       " std        31.705649      43.410323       7.860596  \n",
       " min         4.000000       4.000000       1.000000  \n",
       " 25%        48.000000      44.000000       1.000000  \n",
       " 50%        72.000000      80.000000       1.000000  \n",
       " 75%        96.000000     112.000000       1.000000  \n",
       " max       140.000000     152.000000      20.000000  ,\n",
       "             route_id     difficulty        hold_id     token_num    x    y  \\\n",
       " count  452057.000000  452057.000000  452057.000000  452057.00000  0.0  0.0   \n",
       " mean   106045.795484    1242.255280    1195.662700      13.66654  NaN  NaN   \n",
       " std     65642.474089       4.485806       1.110239       1.12815  NaN  NaN   \n",
       " min         2.000000    1233.000000    1194.000000      12.00000  NaN  NaN   \n",
       " 25%     47390.000000    1239.000000    1195.000000      13.00000  NaN  NaN   \n",
       " 50%    105517.000000    1243.000000    1195.000000      13.00000  NaN  NaN   \n",
       " 75%    162363.000000    1246.000000    1197.000000      15.00000  NaN  NaN   \n",
       " max    222622.000000    1253.000000    1209.000000      31.00000  NaN  NaN   \n",
       " \n",
       "        set_id  \n",
       " count     0.0  \n",
       " mean      NaN  \n",
       " std       NaN  \n",
       " min       NaN  \n",
       " 25%       NaN  \n",
       " 50%       NaN  \n",
       " 75%       NaN  \n",
       " max       NaN  )"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading in a specific board\n",
    "data = get_data(board_name=\"12 x 12 with kickboard Square\")\n",
    "placements = data[\"placements\"]\n",
    "roles = data[\"roles\"]\n",
    "\n",
    "placements.describe(), roles.describe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>route_id</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>hold_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>[42, 156, 94, 169, 115, 201, 84, 181, 68, 184,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>[432, 517, 349, 409, 297, 127, 241, 450, 228, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>[395, 321, 430, 349, 410, 355, 19, 443, 336, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>[278, 324, 493, 262, 344, 373, 461, 481, 412, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>[104, 223, 151, 261, 346, 372, 461, 353, 191, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36474</th>\n",
       "      <td>222597</td>\n",
       "      <td>1</td>\n",
       "      <td>[154, 210, 150, 227, 173, 287, 232, 255, 238, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36475</th>\n",
       "      <td>222600</td>\n",
       "      <td>15</td>\n",
       "      <td>[332, 436, 340, 378, 172, 259, 373, 175, 178, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36476</th>\n",
       "      <td>222614</td>\n",
       "      <td>12</td>\n",
       "      <td>[270, 382, 397, 289, 372, 176, 182, 134, 291]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36477</th>\n",
       "      <td>222618</td>\n",
       "      <td>17</td>\n",
       "      <td>[493, 341, 172, 236, 77, 108]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36478</th>\n",
       "      <td>222622</td>\n",
       "      <td>14</td>\n",
       "      <td>[102, 94, 378, 227, 261, 313, 253, 252, 184, 9...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35010 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       route_id  difficulty                                           hold_ids\n",
       "0             2           6  [42, 156, 94, 169, 115, 201, 84, 181, 68, 184,...\n",
       "1             5           7  [432, 517, 349, 409, 297, 127, 241, 450, 228, ...\n",
       "2            10           8  [395, 321, 430, 349, 410, 355, 19, 443, 336, 3...\n",
       "3            13          11  [278, 324, 493, 262, 344, 373, 461, 481, 412, ...\n",
       "4            16          10  [104, 223, 151, 261, 346, 372, 461, 353, 191, ...\n",
       "...         ...         ...                                                ...\n",
       "36474    222597           1  [154, 210, 150, 227, 173, 287, 232, 255, 238, ...\n",
       "36475    222600          15  [332, 436, 340, 378, 172, 259, 373, 175, 178, ...\n",
       "36476    222614          12      [270, 382, 397, 289, 372, 176, 182, 134, 291]\n",
       "36477    222618          17                      [493, 341, 172, 236, 77, 108]\n",
       "36478    222622          14  [102, 94, 378, 227, 261, 313, 253, 252, 184, 9...\n",
       "\n",
       "[35010 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the id of each hold in the \n",
    "holds_per_route = (\n",
    "    placements.groupby(\"route_id\")\n",
    "    .agg(\n",
    "        difficulty=(\"difficulty\", \"first\"),\n",
    "        hold_ids=(\"hold_id\", list)\n",
    "        )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# filer for routs with less than n holds\n",
    "num_holds = 20\n",
    "holds_per_route = holds_per_route[holds_per_route[\"hold_ids\"].apply(len)< num_holds]\n",
    "\n",
    "# subtracht difficulty offset\n",
    "holds_per_route[\"difficulty\"] = holds_per_route[\"difficulty\"] - holds_per_route[\"difficulty\"].min()\n",
    "holds_per_route\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>route_id</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>...</th>\n",
       "      <th>518</th>\n",
       "      <th>519</th>\n",
       "      <th>520</th>\n",
       "      <th>521</th>\n",
       "      <th>522</th>\n",
       "      <th>523</th>\n",
       "      <th>524</th>\n",
       "      <th>525</th>\n",
       "      <th>526</th>\n",
       "      <th>difficulty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35005</th>\n",
       "      <td>222597</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35006</th>\n",
       "      <td>222600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35007</th>\n",
       "      <td>222614</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35008</th>\n",
       "      <td>222618</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35009</th>\n",
       "      <td>222622</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35010 rows × 478 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       route_id  3  4  5  6  7  8  9  10  11  ...  518  519  520  521  522  \\\n",
       "0             2  0  0  0  0  0  0  0   0   0  ...    0    0    0    0    0   \n",
       "1             5  0  0  0  0  0  0  0   0   0  ...    0    0    0    0    0   \n",
       "2            10  0  0  0  0  0  0  0   0   0  ...    0    0    0    0    0   \n",
       "3            13  0  0  0  0  0  0  0   0   0  ...    0    0    0    0    0   \n",
       "4            16  0  0  0  0  0  0  0   0   0  ...    0    0    0    0    0   \n",
       "...         ... .. .. .. .. .. .. ..  ..  ..  ...  ...  ...  ...  ...  ...   \n",
       "35005    222597  0  0  0  0  0  0  0   0   0  ...    0    0    0    0    0   \n",
       "35006    222600  0  0  0  0  0  0  0   0   1  ...    0    0    0    0    0   \n",
       "35007    222614  0  0  0  0  0  0  0   0   0  ...    0    0    0    0    0   \n",
       "35008    222618  0  0  0  0  0  0  0   0   0  ...    0    0    0    0    0   \n",
       "35009    222622  0  0  0  0  0  0  0   0   0  ...    0    0    0    0    0   \n",
       "\n",
       "       523  524  525  526  difficulty  \n",
       "0        0    0    0    0           6  \n",
       "1        0    0    0    0           7  \n",
       "2        0    0    0    0           8  \n",
       "3        0    0    0    0          11  \n",
       "4        0    0    0    0          10  \n",
       "...    ...  ...  ...  ...         ...  \n",
       "35005    0    0    0    0           1  \n",
       "35006    0    0    0    0          15  \n",
       "35007    0    0    0    0          12  \n",
       "35008    0    0    0    0          17  \n",
       "35009    0    0    0    0          14  \n",
       "\n",
       "[35010 rows x 478 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "one_hot = pd.DataFrame(\n",
    "    mlb.fit_transform(holds_per_route[\"hold_ids\"]),\n",
    "    columns=mlb.classes_,\n",
    "    index=holds_per_route[\"route_id\"]\n",
    ").reset_index()\n",
    "\n",
    "# Add back difficulty column\n",
    "one_hot = one_hot.merge(\n",
    "    holds_per_route[[\"route_id\", \"difficulty\"]],\n",
    "    on=\"route_id\"\n",
    ")\n",
    "\n",
    "one_hot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to /home/fillies/Documents/moon/kilter/data/routes_onehot.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# go up from src/ to project root, then into data/\n",
    "project_root = Path.cwd().parent.parent   # if running from inside src/\n",
    "data_dir = project_root / \"data\"\n",
    "\n",
    "# make sure it exists\n",
    "data_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# save one-hot CSV in data/\n",
    "out_path = data_dir / \"routes_onehot.csv\"\n",
    "one_hot.to_csv(out_path, index=False)\n",
    "\n",
    "print(f\"Saved to {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35010, 21)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# Suppose 'difficulty' is the target\n",
    "X = one_hot.drop(columns=[\"difficulty\", \"route_id\"])\n",
    "y = one_hot[[\"difficulty\"]]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# also encode y in one hot for loss\n",
    "\n",
    "enc = OneHotEncoder(sparse_output=False)\n",
    "y = enc.fit_transform(y)\n",
    "\n",
    "# Make a DataFrame for readability\n",
    "y = pd.DataFrame(\n",
    "    y,\n",
    "    columns=[f\"difficulty_{cls}\" for cls in enc.categories_[0]],\n",
    "    index=one_hot.index\n",
    ")\n",
    "\n",
    "print(y.shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting of Moddel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import EarlyStopping, plot_training_history\n",
    "from models import ShallowMLP\n",
    "from trainer import train_model\n",
    "\n",
    "\n",
    "\n",
    "torch.__version__\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 476]), torch.Size([64, 21]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2, # 20% test, 80% train\n",
    "                                                    random_state=42)\n",
    "\n",
    "X_train = torch.tensor(X_train.values, dtype=torch.float32).to(device)\n",
    "X_test  = torch.tensor(X_test.values, dtype=torch.float32).to(device)\n",
    "y_train = torch.tensor(y_train.values, dtype=torch.float32).to(device)\n",
    "y_test  = torch.tensor(y_test.values, dtype=torch.float32).to(device)\n",
    "\n",
    "train_data = TensorDataset(X_train, y_train)\n",
    "test_data = TensorDataset(X_test, y_test)\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "\n",
    "train_features_batch, train_labels_batch = next(iter(train_loader))\n",
    "train_features_batch.shape, train_labels_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model, history = train_model(\\n    model=shallowMLP,\\n    train_loader=train_loader,\\n    test_loader=test_loader,\\n    loss_fn=loss_fn,\\n    optimizer=optimizer,\\n    acc_fn=acc_fn,\\n    device=device,\\n    epochs=1000,\\n    patience=10\\n)'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shallowMLP = ShallowMLP(input_dim=X_test.shape[1],\n",
    "                        hidden_dim=32,\n",
    "                        num_classes= y_test.shape[1],\n",
    "                        drop_out=0.3\n",
    "                        ).to(device)\n",
    "\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "acc_fn = MulticlassAccuracy(num_classes=21).to(device)\n",
    "optimizer = optim.Adam(shallowMLP.parameters(), lr=1e-3, weight_decay=1e-5 )\n",
    "\n",
    "\"\"\"model, history = train_model(\n",
    "    model=shallowMLP,\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    acc_fn=acc_fn,\n",
    "    device=device,\n",
    "    epochs=1000,\n",
    "    patience=10\n",
    ")\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial: optuna.Trial):\n",
    "    # --- Suggest hyperparameters ---\n",
    "    hidden_dim = trial.suggest_categorical(\"hidden_dim\", [16, 32, 64, 128, 256])\n",
    "    dropout = trial.suggest_categorical(\"dropout\", [0.1, 0.2, 0.3, 0.5])\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-2, log=True)   # log scale\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-6, 1e-3, log=True)\n",
    "\n",
    "    # --- Build model ---\n",
    "    model = ShallowMLP(\n",
    "        input_dim=X_train.shape[1],\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_classes=y_train.shape[1],\n",
    "        drop_out=dropout\n",
    "    ).to(device)\n",
    "\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "    acc_fn = MulticlassAccuracy(num_classes=y_train.shape[1]).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    \n",
    "    checkpoint_path = f\"checkpoints/model_hd{hidden_dim}_do{dropout:.2f}_lr{lr:.4f}_wd{weight_decay:.6f}.pt\"\n",
    "\n",
    "\n",
    "    # --- Train for fewer epochs (fast search) ---\n",
    "    model, history = train_model(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        test_loader=test_loader,\n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optimizer,\n",
    "        acc_fn=acc_fn,\n",
    "        device=device,\n",
    "        epochs=50,      # use small value for tuning\n",
    "        patience=5,\n",
    "        checkpoint_path=checkpoint_path\n",
    "    )\n",
    "\n",
    "    # --- Return final test accuracy ---\n",
    "    return history[\"test_acc\"][-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-18 09:41:13,090] A new study created in memory with name: no-name-88f24ed6-b1ba-4ff5-bda8-dc7c2bd5524d\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=30)\n",
    "\n",
    "print(\"Best trial:\")\n",
    "print(\"  Value:\", study.best_trial.value)\n",
    "print(\"  Params:\", study.best_trial.params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP0YwXo044/NMHL66p2Ai86",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
